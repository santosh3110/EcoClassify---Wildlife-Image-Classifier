---
title: EcoClassify - Wildlife Classifier
emoji: ğŸ¦
colorFrom: green
colorTo: blue
sdk: streamlit
sdk_version: "1.36.0"
app_file: app.py
pinned: false
---

# ğŸ¦‰ EcoClassify â€“ Wildlife Image Classifier  

![Python](https://img.shields.io/badge/python-3.10-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.36.0-ff69b4.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.2-red.svg)
![License](https://img.shields.io/badge/License-Apache%202.0-green.svg)

> **AI-powered wildlife conservation.**  
EcoClassify is an **end-to-end computer vision project** that classifies camera trap images into wildlife species using **transfer learning (ResNet50).**  
It includes **model explainability (Grad-CAM)**, **batch inference**, **fine-tuning via Streamlit UI**, and **MLflow/DagsHub integration** for experiment tracking. It was born out of the need to help researchers, educators, and nature lovers quickly identify species without needing to be a machine learning wizard. This project was developed as part of my internship at **Euron**, with heartfelt thanks to **Sudhanshu Kumar, CEO of Euron,** for his guidance and mentorship.

ğŸ”— **Live Demo on Hugging Face**: [![Hugging Face Spaces](https://img.shields.io/badge/Launch%20App-HuggingFace-orange?logo=huggingface)](https://huggingface.co/spaces/santosh3110/Ecoclassify-Wildlife_Classifier)

---

## ğŸ“¸ App Screenshots  

| Inference (Single Image) | Grad-CAM Explainability |
|---------------------------|--------------------------|
| ![inference](app_inference_tab.png) | ![gradcam](app_gradcam.png) |  

| Batch Inference | Fine-Tuning |
|-----------------|-------------|
| ![batch](app_batch_inf.png) | ![finetune](app_finetune.png) |  

---

## ğŸ“– Table of Contents  

1. [About](#-about)  
2. [Features](#-features)  
3. [Architecture](#-architecture)  
4. [Dataset](#-dataset)  
5. [Installation](#-installation)  
6. [Usage](#-usage)  
7. [Streamlit App](#-streamlit-app)  
8. [Training & Evaluation](#-training--evaluation)  
9. [Explainability](#-explainability)  
10. [Batch Inference](#-batch-inference)  
11. [Fine-Tuning](#-fine-tuning)  
12. [Design Docs](#-design-docs)  
13. [Results](#-results)  
14. [Future Work](#-future-work)  
15. [Acknowledgements](#-acknowledgements)  

---

## ğŸŒ About  

Camera traps capture **millions of images** in wildlife conservation projects. Manual classification is slow, error-prone, and not scalable.  

**EcoClassify** provides:  
- ğŸ”¬ Automated **species classification** (7+ classes + Blank).  
- ğŸ–¼ï¸ **Explainability dashboard** (Grad-CAM heatmaps).  
- âš¡ **Batch inference** for CSV/ZIP datasets.  
- ğŸ›ï¸ **Fine-tuning** interface for custom datasets.  
- ğŸ“Š **MLflow/DagsHub** experiment logging.  

---

## ğŸš€ Features  

- âœ… Species classification: *Antelope_Duiker, Bird, Civet_Genet, Hog, Leopard, Monkey_Prosimian, Rodent, Blank*.  
- âœ… **Transfer learning** with ResNet50 backbone.   
- âœ… **Grad-CAM** explainability for predictions.  
- âœ… **Streamlit app** with multiple tabs: Inference, Batch, Fine-tuning.  
- âœ… **Config-driven training** (YAML params & config).  
- âœ… **Experiment tracking** with MLflow + DagsHub.  

---

## ğŸ—ï¸ Architecture  

### System Architecture  

```mermaid
flowchart TD
    A[User Uploads Image] --> B[Preprocessing & Augmentation]
    B --> C[Model Inference: ResNet50]
    C --> D[Predictions: Species + Confidence ]
    C --> E[Explainability Engine: Grad-CAM]
    D & E --> F[Streamlit Dashboard: Results]
    F --> G[Download CSV / Fine-tune Model]
```

### End-to-End Pipeline  

```mermaid
graph LR
    A[Data Ingestion] --> B[Data Loader]
    B --> C[Training Pipeline with MLflow Logging]
    C --> D[Evaluation of Models with MLflow Logging]
    D --> E[Batch Inference]
    E --> F[Streamlit App]
    F --> G[Model Fine Tuning]
```

### Project Structure  

```
.
EcoClassify---Wildlife-Image-Classifier/
â”‚
â”œâ”€â”€ app.py                     # Streamlit app entry point
â”œâ”€â”€ main.py                    # Orchestrates full training â†’ eval â†’ inference pipeline
â”œâ”€â”€ setup.py                   # Package setup
â”œâ”€â”€ requirements.txt           # Dependencies
â”œâ”€â”€ README.md                  # Documentation
â”œâ”€â”€ LICENSE
â”œâ”€â”€ colab_code.ipynb           # Code for running the repo on Google Colab
â”œâ”€â”€ params.yaml                # Hyperparameters
â”œâ”€â”€ init_project_structure.py  # Script to bootstrap project tree
â”‚
â”œâ”€â”€ artifacts/                 # All experiment outputs
â”‚   â”œâ”€â”€ base_model/            # Initial CNN model
â”‚   â”œâ”€â”€ resnet50_model/        # ResNet50 base model
â”‚   â”œâ”€â”€ training/              # Trained model checkpoints
â”‚   â”œâ”€â”€ prepare_callbacks/     # Callback checkpoints
â”‚   â”œâ”€â”€ evaluation/            # Confusion matrices & reports
â”‚   â”œâ”€â”€ explanations/          # Grad-CAM heatmaps
â”‚   â”œâ”€â”€ batch_inference/       # Batch predictions
â”‚   â”œâ”€â”€ data_ingestion/        # Raw & processed datasets
â”‚   â””â”€â”€ streamlit_outputs/     # Models & mappings saved from app
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml            # Centralized config file
â”‚ 
â”œâ”€â”€ docs/                      # Project Documents
â”‚   â”œâ”€â”€ PRD.pdf                # Product Requirements & Specification Document
â”‚   â”œâ”€â”€ HLD.pdf                # High Level Design Document
â”‚   â””â”€â”€ LLD.pdf                # Low Level Design Document
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ running_logs.log       # Pipeline logs
â”‚
â”œâ”€â”€ research/                  # Notebooks for experiments
â”‚   â””â”€â”€ experiment.ipynb
â”‚   
â”‚
â””â”€â”€ src/ecoclassify/           # Source code (modular package)
    â”œâ”€â”€ components/            # Core ML components
    â”‚   â”œâ”€â”€ customcnn_base_model.py
    â”‚   â”œâ”€â”€ resnet50_model.py
    â”‚   â”œâ”€â”€ training.py
    â”‚   â”œâ”€â”€ evaluation.py
    â”‚   â”œâ”€â”€ explanation_generator.py
    â”‚   â”œâ”€â”€ fine_tuning.py
    â”‚   â”œâ”€â”€ batch_inference.py
    â”‚   â”œâ”€â”€ data_ingestion.py
    â”‚   â””â”€â”€ data_loader.py
    â”‚
    â”œâ”€â”€ pipeline/              # Orchestrated stages
    â”‚   â”œâ”€â”€ stage_01_data_ingestion.py
    â”‚   â”œâ”€â”€ stage_02_customcnn_base_model.py
    â”‚   â”œâ”€â”€ stage_03_resnet_50_model.py
    â”‚   â”œâ”€â”€ stage_04_model_training.py
    â”‚   â”œâ”€â”€ stage_05_model_evaluation.py
    â”‚   â”œâ”€â”€ stage_06_generate_explanations.py
    â”‚   â””â”€â”€ stage_07_batch_inference.py
    â”‚
    â”œâ”€â”€ config/                # Config manager
    â”‚   â””â”€â”€ configuration.py
    â”‚
    â”œâ”€â”€ constants/             # File paths & constants
    â”‚   â””â”€â”€ paths.py
    â”‚
    â”œâ”€â”€ entity/                # Config/data entities
    â”‚   â””â”€â”€ config_entity.py
    â”‚
    â”œâ”€â”€ utils/                 # Utility functions
    â”‚   â”œâ”€â”€ common.py
    â”‚   â””â”€â”€ logger.py
    â”‚
    â””â”€â”€ __init__.py
```

---

## ğŸ“š Dataset  

- **Source**: Conser-vision Practice Area: Image Classification by drivendata.org
- **Provided by**:  
  *The Pan African Programme: The Cultured Chimpanzee, Wild Chimpanzee Foundation, DrivenData. (2022). Conser-vision Practice Area: Image Classification. Retrieved [July 12 2025] from https://www.drivendata.org/competitions/87/competition-image-classification-wildlife-conservation/.*  

---

## âš™ï¸ Installation  

```bash
git clone https://github.com/santosh3110/EcoClassify---Wildlife-Image-Classifier.git
cd EcoClassify---Wildlife-Image-Classifier
conda create -n ecoclassify python=3.10 -y
conda activate ecoclassify
pip install -r requirements.txt
```

(Optional: install PyTorch with CUDA if using GPU).  

---

## â–¶ï¸ Usage  

### Run Streamlit App  

```bash
streamlit run app.py
```

App opens at **http://localhost:8501**.  

### CLI Training  

```bash
python ecoclassify/pipelines/main.py
```

---

## ğŸ–¥ï¸ Streamlit App  

ğŸ‘‰ Try EcoClassify directly without setup: [Live Demo on Hugging Face ğŸš€](https://huggingface.co/spaces/santosh3110/Ecoclassify-Wildlife_Classifier)

Tabs available:  

1. **About** â€“ Project info, dataset, motivation.  
2. **Inference** â€“ Upload images â†’ classification + Grad-CAM heatmaps.  
3. **Batch Inference** â€“ Upload CSV + ZIP â†’ get predictions CSV.  
4. **Fine-Tuning** â€“ Upload dataset (train/val) â†’ retrain ResNet50 with custom hyperparameters.  

---

## ğŸ“Š Model Training & Evaluation  

- Models trained:  
  - **CustomCNN** (100 epochs)  
  - **ResNet50 (transfer learning)** (50 epochs)  

### Results Summary  

| Model      | Dataset     | Accuracy | Notes                     |
|------------|-------------|----------|---------------------------|
| CustomCNN  | Wildlife-8  | 69.8%    | Baseline model, 100 epochs|
| ResNet50   | Wildlife-8  | 89.2%    | Fine-tuned, 50 epochs     |

  - Training visuals:
    - CustomCNN Training Chart: ![customcnn_training.png](customcnn_training.png)
    - ResNet50 Training Chart: ![resnet50_training.png](resnet50_training.png)
  - **Hyperparameters** are controlled via the params.yaml file (no hard-coded values)

- Results tracked via **MLflow & DagsHub**  
  - Dagshub Experiments: https://dagshub.com/santoshkumarguntupalli/EcoClassify---Wildlife-Image-Classifier/experiments
  - MLflow (Dagshub): https://dagshub.com/santoshkumarguntupalli/EcoClassify---Wildlife-Image-Classifier.mlflow/#/experiments/0?searchFilter=&orderByKey=attributes.start_time&orderByAsc=false&startTime=ALL&lifecycleFilter=Active&modelVersionFilter=All+Runs&datasetsFilter=W10%3D

- Evaluation scope:
  - Confusion matrix
  - Classification report
  - Calibration metrics (temperature scaling)
  - **Artifacts** stored under artifacts/

- Results summary (from end-to-end evaluation JSON reports)
  - CustomCNN:
    - Temperature: 0.658
    - Uncalibrated Accuracy: 0.6980
    - Calibrated Accuracy: 0.6980
    - Uncalibrated Log-Loss: 0.8874
    - Calibrated Log-Loss: 0.8300
    - Uncalibrated F1: 0.6919
    - Calibrated F1: 0.6919
  - ResNet50:
    - Temperature: 0.816
    - Uncalibrated Accuracy: 0.8921
    - Calibrated Accuracy: 0.8921
    - Uncalibrated Log-Loss: 0.4058
    - Calibrated Log-Loss: 0.3862
    - Uncalibrated F1: 0.8887
    - Calibrated F1: 0.8890

- Per-class F1 scores (from full_report)
  - CustomCNN:
    - antelope_duiker: 0.503
    - bird: 0.718
    - blank: 0.459
    - civet_genet: 0.856
    - hog: 0.854
    - leopard: 0.887
    - monkey_prosimian: 0.664
    - rodent: 0.700
  - ResNet50:
    - antelope_duiker: 0.813
    - bird: 0.949
    - blank: 0.684
    - civet_genet: 0.958
    - hog: 0.977
    - leopard: 0.962
    - monkey_prosimian: 0.914
    - rodent: 0.917

- Confusion matrices:
  - CustomCNN confusion matrix: ![customcnn_confusion](artifacts/evaluation/customcnn/confusion_matrix.png)
  - ResNet50 confusion matrix: ![resnet50_confusion](artifacts/evaluation/resnet50/confusion_matrix.png)

---

## ğŸ” Explainability  

- **Grad-CAM** highlights model focus regions.  
- Outputs side-by-side comparison:  
  - Original Image  
  - Heatmap Overlay  
- Sample Grad-CAM heatmaps generated on Val dataset:
    ![alt text](artifacts/explanations/ZJ000039_gradcam.png)
    ![alt text](artifacts/explanations/ZJ003443_gradcam.png)
    ![alt text](artifacts/explanations/ZJ013423_gradcam.png)
    ![alt text](artifacts/explanations/ZJ012512_gradcam.png)
---

## ğŸ“¦ Batch Inference  

- Upload **CSV** (image paths) + **ZIP** (images).  
- Pipeline produces **predictions.csv** with class & confidence.  

---

## ğŸ› ï¸ Fine-Tuning  

- Upload dataset in structure:  

```
dataset.zip
 â”œâ”€â”€ train/
 â”‚   â”œâ”€â”€ class1/
 â”‚   â”œâ”€â”€ class2/
 â””â”€â”€ val/
     â”œâ”€â”€ class1/
     â”œâ”€â”€ class2/
```

- Configure hyperparams (epochs, batch size, LR, early stopping).  
- Retrains ResNet50 on uploaded data.  
- Outputs: new model weights + mapping.  

---

## ğŸ“„ Design Docs  

ğŸ“Œ Included in `/docs`:  

- **PRD** â€“ Product Requirements & Specs  
- **HLD** â€“ High-Level Architecture Design  
- **LLD** â€“ Low-Level Implementation Design  

---

## ğŸ§© Future Work  

- ğŸš€ Deploy as **FastAPI + Docker** microservice.  
- ğŸ“± Extend to **mobile app** for field researchers.  
- ğŸ§ª Add **ensemble models** (ResNet + ViT).  
- ğŸ¾ Multi-label support (detect multiple species in one frame).  

---

## â¤ï¸ Acknowledgements  

- The Pan African Programme: The Cultured Chimpanzee, Wild Chimpanzee Foundation, DrivenData. (2022). Conser-vision Practice Area: Image Classification. Retrieved [July 12 2025] from https://www.drivendata.org/competitions/87/competition-image-classification-wildlife-conservation/. 
- Mentorship: **Sudhanshu Kumar (Euron)**  
- Frameworks: PyTorch, Streamlit, MLflow, TorchCAM  

---

## ğŸ“œ License  

Apache 2.0 License Â© 2025 Santosh Kumar Guntupalli  

---

âœ¨ *Made with love for Wildlife & AI* ğŸ†ğŸŒ±  